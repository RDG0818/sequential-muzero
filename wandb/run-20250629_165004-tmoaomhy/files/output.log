Ray cluster started. Available resources: {'node:172.23.48.184': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'CPU': 12.0, 'accelerator_type:G': 1.0, 'object_store_memory': 4030675353.0, 'memory': 9404909159.0}
Waiting for actors to initialize and run one episode...
[36m(LearnerActor pid=42151)[0m (Learner pid=42151) Initializing on GPU...
[36m(LearnerActor pid=42151)[0m (Learner pid=42151) Setup complete.

Warmup phase...
  Buffer size: 980/1000
Warmup complete. Time Taken 0.84 seconds. Starting main training loop.
Traceback (most recent call last):
  File "/home/ryan/toy_mazero/train.py", line 467, in <module>
    main()
  File "/home/ryan/toy_mazero/train.py", line 437, in main
    loss_dict = ray.get(done_learner_refs[0])
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/worker.py", line 2849, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/worker.py", line 937, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

[36mray::LearnerActor.train()[39m (pid=42151, ip=172.23.48.184, actor_id=25d4e0bb607b743244e124ee01000000, repr=<train.LearnerActor object at 0x799460212800>)
  File "/home/ryan/toy_mazero/train.py", line 190, in train
    self.params, self.opt_state, metrics, new_priorities = self.jitted_train_step(self.model, self.optimizer, self.params, self.opt_state, jax_batch,
  File "/home/ryan/toy_mazero/train.py", line 171, in train_step
    (loss, (metrics, td_error)), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)
  File "/home/ryan/toy_mazero/train.py", line 129, in loss_fn
    model_output = model.apply(
  File "/home/ryan/toy_mazero/model/model.py", line 227, in __call__
    batch_size, num_agents, _ = observations.shape
ValueError: not enough values to unpack (expected 3, got 2)
Traceback (most recent call last):
  File "/home/ryan/toy_mazero/train.py", line 467, in <module>
    main()
  File "/home/ryan/toy_mazero/train.py", line 437, in main
    loss_dict = ray.get(done_learner_refs[0])
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/worker.py", line 2849, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/ryan/miniconda3/envs/jaxmarl_env/lib/python3.10/site-packages/ray/_private/worker.py", line 937, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

[36mray::LearnerActor.train()[39m (pid=42151, ip=172.23.48.184, actor_id=25d4e0bb607b743244e124ee01000000, repr=<train.LearnerActor object at 0x799460212800>)
  File "/home/ryan/toy_mazero/train.py", line 190, in train
    self.params, self.opt_state, metrics, new_priorities = self.jitted_train_step(self.model, self.optimizer, self.params, self.opt_state, jax_batch,
  File "/home/ryan/toy_mazero/train.py", line 171, in train_step
    (loss, (metrics, td_error)), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)
  File "/home/ryan/toy_mazero/train.py", line 129, in loss_fn
    model_output = model.apply(
  File "/home/ryan/toy_mazero/model/model.py", line 227, in __call__
    batch_size, num_agents, _ = observations.shape
ValueError: not enough values to unpack (expected 3, got 2)
[36m(DataActor pid=42150)[0m [32m2025-06-29 16:50:27[0m | [36mDEBUG[0m | [36mUpdating parameters from learner.[0m
