CONFIG = { 
            "env_name": "MPE_simple_spread_v3",
            "planner_mode": "joint",  # "independent" or "joint"
            "num_episodes": 500000,
            "warmup_episodes": 1000,
            "log_interval": 100,
            "num_actors": 6, 
            "num_agents": 3,
            "max_episode_steps": 25,
            "num_simulations": 50,
            "num_joint_samples": 16,
            "max_depth_gumbel_search": 10,
            "num_gumbel_samples": 10,
            "replay_buffer_size": 20000,
            "batch_size": 256,
            "learning_rate": 1e-4,
            "param_update_interval": 10,
            "end_lr_factor": 0.1,
            "lr_warmup_steps": 5000,
            "value_loss_coefficient": 0.5,
            "gradient_clip_norm": 5.0,
            "unroll_steps": 5,
            "discount_gamma": 0.99,
            "value_support_size": 300,
            "reward_support_size": 300,
            "hidden_state_size": 128,
            "fc_representation_layers": (128,),
            "fc_dynamic_layers": (128,),
            "fc_reward_layers": (32,),
            "fc_value_layers": (32,),
            "fc_policy_layers": (32,)}